# 1. 라이브러리 설치
!pip install -q albumentations

# 2. 임포트
import os
import random
import numpy as np
import pandas as pd
from PIL import Image
import matplotlib.pyplot as plt
import seaborn as sns
import torch
from torch import nn
from torch.utils.data import Dataset, DataLoader
import albumentations as A
from albumentations.pytorch import ToTensorV2
from sklearn.metrics import accuracy_score, f1_score, confusion_matrix



# 랜덤 시드 고정
SEED = 42
random.seed(SEED)
np.random.seed(SEED)
torch.manual_seed(SEED)
torch.backends.cudnn.deterministic = True
torch.backends.cudnn.benchmark = False

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')


# 하이퍼파라미터
BATCH_SIZE  = 32  # 미니 배치 크기
NUM_EPOCHS  = 50
PATIENCE    = 5
LEARNING_RATE = 1e-3




# 3. 데이터 읽기
csv_path = '/kaggle/input/atos-dataset/ATOS/train.csv'
img_dir  = '/kaggle/input/atos-dataset/ATOS/train_images'
df       = pd.read_csv(csv_path)

# 이미지 파일 존재 여부 체크 함수
def exists_image(fname):
    return os.path.exists(os.path.join(img_dir, fname))

# 4. 클래스별 샘플링 (300개 랜덤 추출 → 존재하는 200개 사용)
train_list = []
test_list  = []
for lbl in df['label'].unique():
    subset_all = df[df['label'] == lbl]
    # 300개 랜덤 추출 (모집단 < 300 시 복원추출)
    replace300 = len(subset_all) < 300
    initial300 = subset_all.sample(n=300, replace=replace300, random_state=SEED)

    # 실제 존재하는 파일만 남김
    exist300 = initial300[initial300['image'].apply(exists_image)]
    # TRAIN: 상위 200개
    if len(exist300) >= 200:
        train_samp = exist300.sample(n=200, random_state=SEED)
    else:
        # 부족 시 복원추출로 보충
        needed = 200 - len(exist300)
        if len(exist300) > 0:
            extra = exist300.sample(n=needed, replace=True, random_state=SEED)
            train_samp = pd.concat([exist300, extra], ignore_index=True)
        else:
            # 존재 샘플이 전무할 때는 전체 존재 집합에서 추출
            exist_all = subset_all[subset_all['image'].apply(exists_image)]
            replace_flag = len(exist_all) < 200
            train_samp = exist_all.sample(n=200, replace=replace_flag, random_state=SEED)
    train_list.append(train_samp)

    # TEST: 나머지에서 100개 (모집단 <100 시 복원추출)
    remaining = exist300.drop(train_samp.index, errors='ignore')
    replace100 = len(remaining) < 100
    if len(remaining) >= 100:
        test_samp = remaining.sample(n=100, random_state=SEED)
    else:
        # 부족분 복원추출
        if len(remaining) > 0:
            needed = 100 - len(remaining)
            extra = remaining.sample(n=needed, replace=True, random_state=SEED)
            test_samp = pd.concat([remaining, extra], ignore_index=True)
        else:
            # 남은이 없을 때 전체 exist_all에서
            exist_all = subset_all[subset_all['image'].apply(exists_image)]
            replace_flag = len(exist_all) < 100
            test_samp = exist_all.sample(n=100, replace=replace_flag, random_state=SEED)
    test_list.append(test_samp)

train_df = pd.concat(train_list).reset_index(drop=True)
test_df  = pd.concat(test_list).reset_index(drop=True)
val_df  = pd.concat(test_list).reset_index(drop=True)

# 5. Dataset 정의
class ATOSDataset(Dataset):
    def __init__(self, df, img_dir, transforms=None):
        self.df = df.reset_index(drop=True)
        self.img_dir = img_dir
        self.transforms = transforms
    def __len__(self):
        return len(self.df)
    def __getitem__(self, idx):
        row = self.df.iloc[idx]
        img_path = os.path.join(self.img_dir, row['image'])
        image = np.array(Image.open(img_path).convert('RGB'))
        if self.transforms:
            image = self.transforms(image=image)['image']
        label = int(row['label'])
        return image, label

# 6. Augmentation 정의
def get_transforms(mode='train'):
    if mode == 'train':
        return A.Compose([
            A.RandomResizedCrop(size=(224, 224), scale=(0.8, 1.0), ratio=(0.75, 1.3333), p=1.0),
            A.HorizontalFlip(p=0.5),
            A.VerticalFlip(p=0.3),
            A.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1, p=0.5),
            A.GaussNoise(p=0.2),
            A.CLAHE(clip_limit=2.0, p=0.2),
            A.Resize(height=224, width=224),
            A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),
            ToTensorV2()
        ])
    else:
        return A.Compose([
            A.Resize(height=224, width=224),
            A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),
            ToTensorV2()
        ])

# 7. DataLoader 생성
# train_ds = ATOSDataset(train_df, img_dir, transforms=get_transforms('train'))
# test_ds  = ATOSDataset(test_df, img_dir, transforms=get_transforms('val'))
# train_loader = DataLoader(train_ds, batch_size=32, shuffle=True, num_workers=4)
# test_loader  = DataLoader(test_ds,  batch_size=32, shuffle=False, num_workers=4)

train_ds      = ATOSDataset(train_df, img_dir, transforms=get_transforms('train'))
val_ds        = ATOSDataset(val_df,   img_dir, transforms=get_transforms('val'))
train_loader  = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True,  num_workers=4)
val_loader    = DataLoader(val_ds,   batch_size=BATCH_SIZE, shuffle=False, num_workers=4)



# 8. ResNet18-CBAM 모델 정의
class BasicConv(nn.Module):
    def __init__(self, in_planes, out_planes, kernel_size, stride, padding=0, dilation=1, relu=True):
        super().__init__()
        self.conv = nn.Conv2d(in_planes, out_planes, kernel_size, stride, padding, dilation=dilation, bias=False)
        self.bn = nn.BatchNorm2d(out_planes)
        self.relu = nn.ReLU(inplace=True) if relu else nn.Identity()
    def forward(self, x): return self.relu(self.bn(self.conv(x)))

class ChannelAttention(nn.Module):
    def __init__(self, in_planes, ratio=16):
        super().__init__()
        self.avg = nn.AdaptiveAvgPool2d(1)
        self.max = nn.AdaptiveMaxPool2d(1)
        self.fc  = nn.Sequential(
            nn.Conv2d(in_planes, in_planes//ratio,1,bias=False),
            nn.ReLU(),
            nn.Conv2d(in_planes//ratio, in_planes,1,bias=False)
        )
        self.sig = nn.Sigmoid()
    def forward(self, x): return self.sig(self.fc(self.avg(x)) + self.fc(self.max(x)))

class SpatialAttention(nn.Module):
    def __init__(self, kernel_size=7):
        super().__init__()
        self.conv = nn.Conv2d(2,1,kernel_size,padding=kernel_size//2,bias=False)
        self.sig  = nn.Sigmoid()
    def forward(self, x):
        avg = torch.mean(x, dim=1, keepdim=True); max_, _ = torch.max(x, dim=1, keepdim=True)
        return self.sig(self.conv(torch.cat([avg, max_], dim=1)))

class CBAM(nn.Module):
    def __init__(self, in_planes, ratio=16, kernel_size=7):
        super().__init__()
        self.ca = ChannelAttention(in_planes, ratio)
        self.sa = SpatialAttention(kernel_size)
    def forward(self, x): return x * self.ca(x) * self.sa(x)

class BasicBlock(nn.Module):
    expansion = 1
    def __init__(self, in_planes, planes, stride=1):
        super().__init__()
        self.conv1 = BasicConv(in_planes, planes, 3, stride, padding=1)
        self.conv2 = BasicConv(planes, planes, 3, 1, padding=1, relu=False)
        self.cbam  = CBAM(planes)
        self.shortcut = nn.Sequential()
        if stride != 1 or in_planes != planes:
            self.shortcut = nn.Sequential(
                nn.Conv2d(in_planes, planes, 1, stride, bias=False),
                nn.BatchNorm2d(planes)
            )
    def forward(self, x):
        out = self.conv1(x)
        out = self.conv2(out)
        out = self.cbam(out)
        out += self.shortcut(x)
        return nn.ReLU(inplace=True)(out)

class ResNet18_CBAM(nn.Module):
    def __init__(self, num_classes):
        super().__init__()
        self.in_planes  = 64
        self.conv1      = BasicConv(3, 64, 7, 2, padding=3)
        self.maxpool    = nn.MaxPool2d(3, 2, padding=1)
        self.layer1     = self._make_layer(64,  2, stride=1)
        self.layer2     = self._make_layer(128, 2, stride=2)
        self.layer3     = self._make_layer(256, 2, stride=2)
        self.layer4     = self._make_layer(512, 2, stride=2)
        self.avgpool    = nn.AdaptiveAvgPool2d(1)
        self.fc         = nn.Linear(512*BasicBlock.expansion, num_classes)
    def _make_layer(self, planes, blocks, stride):
        strides = [stride] + [1]*(blocks-1)
        layers  = []
        for s in strides:
            layers.append(BasicBlock(self.in_planes, planes, s))
            self.in_planes = planes * BasicBlock.expansion
        return nn.Sequential(*layers)
    def forward(self, x):
        x = self.conv1(x)
        x = self.maxpool(x)
        x = self.layer1(x)
        x = self.layer2(x)
        x = self.layer3(x)
        x = self.layer4(x)
        x = self.avgpool(x)
        x = torch.flatten(x, 1)
        return self.fc(x)

# 9. 모델 생성 및 옵티마이저/스케줄러 정의
num_classes = df['label'].nunique()
model       = ResNet18_CBAM(num_classes).to(device)
criterion   = nn.CrossEntropyLoss()
optimizer   = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=1e-4)
scheduler   = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)


# 10. 학습 루프
# num_epochs = 20
# for epoch in range(num_epochs):
#     model.train()
#     running_loss = 0.0
#     for imgs, labels in train_loader:
#         imgs, labels = imgs.to(device), labels.to(device)
#         optimizer.zero_grad()
#         outputs = model(imgs)
#         loss    = criterion(outputs, labels)
#         loss.backward()
#         optimizer.step()
#         running_loss += loss.item() * imgs.size(0)
#     scheduler.step()
#     epoch_loss = running_loss / len(train_loader.dataset)
#     print(f"Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}")


# 10. 학습 루프 with Early Stopping
best_val_loss = float('inf')
patience      = 5
counter       = 0
num_epochs    = 50
for epoch in range(num_epochs):
    # ---- Training ----
    model.train()
    train_loss = 0.0
    for imgs, labels in train_loader:
        imgs, labels = imgs.to(device), labels.to(device)
        optimizer.zero_grad()
        outputs = model(imgs)
        loss    = criterion(outputs, labels)
        loss.backward()
        optimizer.step()
        train_loss += loss.item() * imgs.size(0)
    train_loss /= len(train_loader.dataset)

    # ---- Validation ----
    model.eval()
    val_loss = 0.0
    correct  = 0
    total    = 0
    with torch.no_grad():
        for imgs, labels in val_loader:
            imgs, labels = imgs.to(device), labels.to(device)
            outputs      = model(imgs)
            loss         = criterion(outputs, labels)
            val_loss    += loss.item() * imgs.size(0)
            preds        = outputs.argmax(dim=1)
            correct     += (preds == labels).sum().item()
            total       += labels.size(0)
    val_loss /= len(val_loader.dataset)
    val_acc   = correct / total

    print(f"Epoch {epoch+1}/{num_epochs}"
          f", Train Loss: {train_loss:.4f}"
          f", Val Loss: {val_loss:.4f}"
          f", Val Acc: {val_acc:.4f}")

    # Early Stopping 체크
    if val_loss < best_val_loss:
        best_val_loss = val_loss
        counter       = 0
        torch.save(model.state_dict(), 'best_model.pth')
    else:
        counter += 1
        if counter >= patience:
            print("Early stopping triggered.")
            break




# 11. 평가: 예측 및 지표 계산
model.eval()
all_preds, all_labels = [], []
with torch.no_grad():
    for imgs, labels in val_loader:
        imgs, labels = imgs.to(device), labels.to(device)
        preds = model(imgs).argmax(dim=1)
        all_preds.extend(preds.cpu().numpy())
        all_labels.extend(labels.cpu().numpy())

acc      = accuracy_score(all_labels, all_preds)
f1_macro = f1_score(all_labels, all_preds, average='macro')
cm       = confusion_matrix(all_labels, all_preds)
print(f"Accuracy: {acc:.4f} | F1 (macro): {f1_macro:.4f}")
print("Confusion Matrix:")
print(cm)




# 12. 평가: 예측 및 메트릭 계산

plt.figure(figsize=(8,6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
plt.title('Confusion Matrix')
plt.xlabel('Predicted')
plt.ylabel('True')
plt.show()


# 13. 정확히 예측된 이미지 10개 시각화
correct_indices = [i for i,(p,t) in enumerate(zip(all_preds, all_labels)) if p == t]
sample_indices  = random.sample(correct_indices, min(10, len(correct_indices)))

fig, axes = plt.subplots(2,5, figsize=(15,6))
for ax, idx in zip(axes.flatten(), sample_indices):
    row     = test_df.iloc[idx]
    img_path= os.path.join(img_dir, row['image'])
    img     = Image.open(img_path).convert('RGB')
    ax.imshow(img)
    ax.set_title(f"Pred: {all_preds[idx]}, True: {all_labels[idx]}")
    ax.axis('off')
plt.tight_layout()
plt.show()
